### This file was generated by Nexus Schema
### Do not make changes to this file directly


"""Return the entire crawling data."""
type CrawledData {
  """List of found urls."""
  crawledData: [String!]!

  """Crawl current status."""
  isCrawling: Boolean!

  """The base url."""
  url: String!
}

"""The return type for the crawler Status subscription."""
type CrawlerStatusData {
  """List of urls currently being crawled."""
  currentlyCrawled: [String!]!

  """Urls done crawling."""
  doneCrawled: Int!
}

"""Input parameters for the crawlUrl query"""
input CrawlUrlInput {
  """Delay for the crawler"""
  delay: Int = 0

  """The maximum amount of crawled URLs per crawl."""
  maxUrls: Int = 100

  """Base url for the crawler."""
  url: String
}

"""
A date string, such as 2007-12-03, compliant with the `full-date` format outlined in section 5.6 of the RFC 3339 profile of the ISO 8601 standard for representation of dates and times using the Gregorian calendar.
"""
scalar Date

"""
The `JSONObject` scalar type represents JSON objects as specified by [ECMA-404](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf).
"""
scalar JSONObject @specifiedBy(url: "http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf")

type Query {
  """Start a crawler for a given URL"""
  crawlUrl(input: CrawlUrlInput): String!

  """Generate a sitemap for a crawled URL."""
  generateSitemap(
    """
    Wether or not we want to include the Crawled externals links. A valid Sitemap XML shouldn't include them.
    """
    externalLinks: Boolean = false

    """
    This needs to be a crawled URL, ie crawlUrl needs to finish running first.
    """
    url: String!
  ): SiteMapData!

  """Return a paginated list of Crawled Data."""
  getCrawledData(
    """Skip the first n elements."""
    skip: Int = 0

    """Take n elements."""
    take: Int = 5
  ): [CrawledData!]!
  ok: Boolean!
}

"""Sitemap in XML and JSON."""
type SiteMapData {
  """Crawled Data JSON array."""
  json: JSONObject!

  """XML Sitemap string."""
  xml: String!
}

type Subscription {
  """
  Subscribtion endpoint that gives information about the ongoing crawling operations.
  """
  crawlerStatus: CrawlerStatusData!
}
